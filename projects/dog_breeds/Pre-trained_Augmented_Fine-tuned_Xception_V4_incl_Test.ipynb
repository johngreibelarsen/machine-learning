{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the bottleneck features of a pre-trained network along with data argumentation plus base model fine-tuning for classifying Dog Breeds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this short book we will investigate the effect of how data argumentation, transfer learning and fine tuning of pre-trained network can help us achieve high accuracy for predicting the dog breed given a dog image with the additional caveat that we only have a sparse dataset available.\n",
    "\n",
    "We will consider 133 dogbreeds consisting of:\n",
    "- 6680 training dog images (avg. of 50 per class)\n",
    "- 835 validation dog images (avg. of 6 per class)\n",
    "- 836 test dog images (avg. of 6 per class)\n",
    "\n",
    "\n",
    "We will start out by transfer learning from imagenet. We check to see the effect of using below optimizer for the transfer learning: <br>\n",
    "> __model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])__<br>\n",
    "\n",
    "For fine tuning the last layers in the pre-trained network we use the stochastic gradient descent optimizer with low learning rates (and variable learning rates) and decays while keeping a high momentum of 0.9: <br>\n",
    ">  __sgd = SGD(lr=lr, decay=decay, momentum=0.9, nesterov=True)__ <br>\n",
    ">  __model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])__ <br>\n",
    "\n",
    "where lr = learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception architecture\n",
    "\n",
    "The architecture has 36 convolutional stages, illustrated below:\n",
    "<img src=./Xception_architecture.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Xception model summary\n",
    "\n",
    "The base model and its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, None, None, 32 128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, None, None, 32 0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, None, None, 64 18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, None, None, 64 256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, None, None, 64 0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, None, None, 12 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, None, None, 12 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, None, None, 12 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, None, None, 12 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, None, None, 12 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 12 8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, None, None, 12 0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 12 512         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, None, None, 12 0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, None, None, 12 0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, None, None, 25 33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, None, None, 25 0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, None, None, 25 67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, None, None, 25 1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 25 32768       add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, None, None, 25 0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 25 1024        conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, None, None, 25 0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, None, None, 25 0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, None, None, 72 188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, None, None, 72 0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 72 186368      add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, None, None, 72 0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 72 2912        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, None, None, 72 0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, None, None, 72 0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, None, None, 72 0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, None, None, 72 0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, None, None, 72 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, None, None, 72 0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, None, None, 72 0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, None, None, 72 0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, None, None, 72 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, None, None, 72 0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, None, None, 72 0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, None, None, 72 0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, None, None, 72 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, None, None, 72 0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, None, None, 72 0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, None, None, 72 0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, None, None, 72 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, None, None, 72 0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, None, None, 72 0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, None, None, 72 0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, None, None, 72 536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, None, None, 72 2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, None, None, 72 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, None, None, 72 0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, None, None, 72 0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, None, None, 72 0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, None, None, 72 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, None, None, 72 0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, None, None, 72 0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, None, None, 72 0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, None, None, 72 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, None, None, 72 0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, None, None, 72 0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, None, None, 72 0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, None, None, 72 536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, None, None, 72 2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, None, None, 72 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, None, None, 72 0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, None, None, 72 536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, None, None, 72 2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, None, None, 72 0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, None, None, 10 752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, None, None, 10 4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 10 745472      add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, None, None, 10 0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 10 4096        conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, None, None, 10 0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, None, None, 15 1582080     add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, None, None, 15 6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, None, None, 15 0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, None, None, 20 3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, None, None, 20 8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, None, None, 20 0           block14_sepconv2_bn[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "base_model = Xception(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The structure of our training, validation and test datasets are illustrated below. This structure are dictated by using the ImageDataGenerator and flow_from_directory() functionality of Keras, so we need to create a directory structure where images of each class sits within its own sub-directory in the training, validation and test directories.\n",
    "\n",
    "<img src=./Image_structure_hl.png>\n",
    "\n",
    "<img src=./Image_structure_ll.png>\n",
    "\n",
    "<img src=./Image_structure_details.png>\n",
    "\n",
    "Make sure all the sub-directories (classes) in the training set are present in the validation and test set also. And, remember that the names of the sub-directories will be the names of your classes (labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "The constants of our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The pixel size we will use for our images (of various resolution)\n",
    "WIDTH, HEIGHT = 299, 299\n",
    "\n",
    "# Number of epochs to train model on\n",
    "EPOCHS = 5\n",
    "\n",
    "# Batch size used by flow_from_directory and predict_generator \n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Note: For each batch, gradients will be computed and updates will be made \n",
    "# to the weights of the network automatically. One iteration over all the \n",
    "# training set is referred to as an epoch\n",
    "\n",
    "# Layer from which we will start retraining our already pretrained base model (Xception, Inception or .. whatever)\n",
    "LAYERS_TO_FREEZE = 126 # We will come in before block 14\n",
    "\n",
    "# Note for Inception_V3 a suitable value be around NB_IV3 = 172, at least to start with\n",
    "\n",
    "# The number of outcome classes, that is, number of dog breeds\n",
    "NO_OF_CLASSES = 133\n",
    "\n",
    "# location of the directiories containing the same classes\n",
    "TRAIN_DATA_DIR = 'dogImages/train'\n",
    "VALID_DATA_DIR = 'dogImages/valid'\n",
    "TEST_DATA_DIR = 'dogImages/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The top layer\n",
    "\n",
    "Now we introduce a small fully-connected network - the top model. We will keep the top model small and light as we are only interested in seeing how the transfer learned and the fine tuned models perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model  \n",
    "from keras.layers import Dropout, Dense, GlobalAveragePooling2D  \n",
    "\n",
    "top_layer = base_model.output\n",
    "top_layer = GlobalAveragePooling2D()(top_layer)\n",
    "top_layer = Dropout(0.5)(top_layer)\n",
    "top_layer = Dense(256, activation='relu')(top_layer) \n",
    "top_layer = Dropout(0.5)(top_layer)\n",
    "top_layer = Dense(NO_OF_CLASSES, activation='softmax')(top_layer) \n",
    "\n",
    "# Combine the base and top model\n",
    "model = Model(inputs=base_model.input, outputs=top_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze all layers in the base model and compile the entire model\n",
    "def use_transfer_learning():\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for fine-tuning base model\n",
    "\n",
    "The features learned by low-level convolutional blocks are more general, less abstract than those found higher-up, so it is sensible to only fine-tune the last blocks/layers (more specialized features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# Allow any layer after LAYERS_TO_FREEZE to get re-trained on our dataset. Fine-tuning \n",
    "# should be done with a very slow learning rate, and typically with the SGD optimizer \n",
    "# rather than an adaptative learning rate optimizer such as RMSProp. This is to make \n",
    "# sure that the magnitude of the updates stays very small, so as not to wreck the \n",
    "# previously learned features. \n",
    "def use_finetuning(lr, decay):    \n",
    "    for layer in base_model.layers[:LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image Generators\n",
    "\n",
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6650 images belonging to 133 classes.\n",
      "Found 830 images belonging to 133 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen =  ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30, # value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "    width_shift_range=0.2,  # ranges (fraction of total width or height) within which to randomly translate \n",
    "    height_shift_range=0.2, # pictures vertically or horizontally\n",
    "    zoom_range=0.2, # randomly zooming inside pictures\n",
    "    horizontal_flip=True # randomly flipping half of the images horizontally\n",
    ")\n",
    "\n",
    "# this is the augmentation configuration we will use for training    \n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# this is a generator that will read pictures found in subfolders of 'data/train', \n",
    "# and indefinitely generate batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size=(WIDTH, HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    VALID_DATA_DIR,\n",
    "    target_size=(WIDTH, HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time\n",
    "\n",
    "In summary:\n",
    "- to perform fine-tuning, all layers should start with properly trained weights  so we find the weights via transfer learning before fine-tuning, that is, the large gradient updates triggered by randomly initialized weights would wreck the learned weights in the convolutional base. In our case this is why we first train the top-level classifier, and only then start fine-tuning convolutional weights alongside it.\n",
    "- we choose to only fine-tune the last convolutional block rather than the entire network in order to prevent overfitting, since the entire network would have a very large entropic capacity and thus a strong tendency to overfit. The features learned by low-level convolutional blocks are more general, less abstract than those found higher-up, so it is sensible to keep the first few blocks fixed (more general features) and only fine-tune the last one (more specialized features).\n",
    "- fine-tuning should typically be done with a slow learning rate, and typically with the SGD optimizer rather than an adaptative learning rate optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfer learning starting...\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 235s - loss: 2.9312 - acc: 0.3665 - val_loss: 0.9408 - val_acc: 0.7398\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 233s - loss: 1.3706 - acc: 0.6132 - val_loss: 0.7342 - val_acc: 0.7598\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 233s - loss: 1.1035 - acc: 0.6800 - val_loss: 0.6168 - val_acc: 0.8032\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 233s - loss: 1.0246 - acc: 0.7088 - val_loss: 0.5880 - val_acc: 0.8092\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 233s - loss: 0.9716 - acc: 0.7214 - val_loss: 0.5696 - val_acc: 0.8133\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGdRJREFUeJzt3X+UXGWd5/H3h0464XcG0kpI0gQ1KiqK0ESa8KNnkDGO\nmJxdOLOBVScqxnU2M4zDrAsuqwiuOGdnnR0dRodlPaIMAsuMbgZxGQfoIUCD6YzAkCAYM0x+DJgQ\nICT8SOjw3T+e23Sl6O6q6q4f3U8+r3Pu6bp1n6r7rae6PnXrubduKSIwM7O8HNDqAszMrP4c7mZm\nGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4Z0xSm6Rdkjrr2baVJL1FUt2P35X0fklPlMw/Jun0atqO\nYV3XSvr8WG9vVo0prS7AhkjaVTJ7ELAb2FvMfzoi/qqW+4uIvcAh9W67P4iIt9XjfiRdCHwkInpK\n7vvCety32Wgc7hNIRLwWrsWW4YUR8fcjtZc0JSIGmlGbWSX+f5xYPCwziUj6sqSbJH1f0k7gI5K6\nJd0v6TlJT0r6uqSpRfspkkLSvGL++mL5jyXtlNQn6dha2xbLPyjpcUk7JH1D0r2Slo1QdzU1flrS\neknPSvp6yW3bJP2ppO2SNgCLRumf/yLpxrLrrpb0teLyhZIeLR7PL4ut6pHua7OknuLyQZK+V9S2\nFjiprO1lkjYU97tW0uLi+uOBPwdOL4a8ni7p28tLbv8fise+XdIPJc2qpm9q6efBeiT9vaRnJD0l\n6XMl6/mvRZ88L6lf0tHDDYFJumfweS768+5iPc8Al0maL+muYh1PF/12eMntjyke47Zi+Z9Jml7U\nfFxJu1mSXpR05EiP1yqICE8TcAKeAN5fdt2XgT3Ah0lvzAcCJwPvI30KexPwOLCiaD8FCGBeMX89\n8DTQBUwFbgKuH0PbNwA7gSXFsj8EXgGWjfBYqqnx/wKHA/OAZwYfO7ACWAvMAY4E7k7/tsOu503A\nLuDgkvveCnQV8x8u2gj4DeAl4N3FsvcDT5Tc12agp7j8J0Av8GvAMcC6sra/DcwqnpMLihreWCy7\nEOgtq/N64PLi8m8WNZ4ATAf+Arizmr6psZ8PB34FXARMAw4DFhTLLgUeAuYXj+EE4AjgLeV9Ddwz\n+DwXj20A+AzQRvp/fCtwFtBe/J/cC/xJyeN5pOjPg4v2C4tl1wD/rWQ9FwM/aPXrcDJPLS/A0whP\nzMjhfmeF2/0R8H+Ky8MF9rdK2i4GHhlD208Aq0qWCXiSEcK9yhpPKVn+N8AfFZfvJg1PDS77rfLA\nKbvv+4ELissfBB4bpe2twH8sLo8W7htLnwvgd0vbDnO/jwAfKi5XCvfrgK+ULDuMtJ9lTqW+qbGf\nPwqsHqHdLwfrLbu+mnDfUKGG8wbXC5wOPAW0DdNuIfDPgIr5B4F/W+/X1f40eVhm8tlUOiPp7ZJ+\nVHzMfh64Apg5yu2fKrn8IqPvRB2p7dGldUR6NW4e6U6qrLGqdQH/Mkq9ADcA5xeXLyjmB+s4R9ID\nxZDBc6St5tH6atCs0WqQtEzSQ8XQwnPA26u8X0iP77X7i4jngWeB2SVtqnrOKvTzXFKID2e0ZZWU\n/z8eJelmSVuKGr5TVsMTkXbe7yMi7iV9CjhN0ruATuBHY6zJ8Jj7ZFR+GOBfkrYU3xIRhwFfIG1J\nN9KTpC1LACSJfcOo3HhqfJIUCoMqHap5M/B+SbNJw0Y3FDUeCNwCXEUaMpkB/F2VdTw1Ug2S3gR8\nkzQ0cWRxvz8vud9Kh23+K2moZ/D+DiUN/2ypoq5yo/XzJuDNI9xupGUvFDUdVHLdUWVtyh/fH5OO\n8jq+qGFZWQ3HSGoboY7vAh8hfcq4OSJ2j9DOquBwn/wOBXYALxQ7pD7dhHXeCpwo6cOSppDGcTsa\nVOPNwB9Iml3sXPvPozWOiKdIQwffIQ3J/KJYNI00DrwN2CvpHNLYcLU1fF7SDKXvAawoWXYIKeC2\nkd7nPkXach/0K2BO6Y7NMt8HPinp3ZKmkd58VkXEiJ+ERjFaP68EOiWtkDRN0mGSFhTLrgW+LOnN\nSk6QdATpTe0p0o77NknLKXkjGqWGF4AdkuaShoYG9QHbga8o7aQ+UNLCkuXfIw3jXEAKehsHh/vk\ndzHwO6QdnH9J2vHZUBHxK+DfAV8jvVjfDPyMtMVW7xq/CdwB/BOwmrT1XckNpDH014ZkIuI54LPA\nD0g7Jc8jvUlV44ukTxBPAD+mJHgi4mHgG8BPizZvAx4oue1PgF8Av5JUOrwyePv/Rxo++UFx+07g\n31dZV7kR+zkidgBnA+eS3nAeB84sFv934Iekfn6etHNzejHc9ing86Sd628pe2zD+SKwgPQmsxL4\n65IaBoBzgONIW/EbSc/D4PInSM/z7oi4r8bHbmUGd16YjVnxMftfgfMiYlWr67HJS9J3STtpL291\nLZOdv8RkYyJpEenIlJdIh9K9Qtp6NRuTYv/FEuD4VteSAw/L2FidBmwgjTV/APg33gFmYyXpKtKx\n9l+JiI2tricHHpYxM8uQt9zNzDLUsjH3mTNnxrx581q1ejOzSWnNmjVPR8Rohx4DLQz3efPm0d/f\n36rVm5lNSpIqfUsb8LCMmVmWHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcgnDjMzG04E\n7N0Le/ZUN73ySvVtzzkHTj65oeU73M2suWoJzHoE6XimRp17a9Ysh7uZ1VEE7N4NL71Uv+nll2sL\nzFdfbcxjmzoV2turmw46qPq27e213XelacoUUKN/CdPhbtZaAwP1DdrRAnjw71i3Rtva4MADh5+m\nTYPDDht/8I01RKdObUpgTiZVhXvxwwx/BrQB10bEV8uWdwLXATOKNpdExG11rtWsOZ5/HnbubE7g\nDgyMvc7ScJ0+fd/5I44YOYjHOk3xtuBkUvHZKn5C7WrS7y9uBlZLWhkR60qaXUb6tfJvSnoHcBsw\nrwH1mtXfU09Bb2+a7roLHn+89vuYOnXkUDz4YDjyyPoG7bRp3lK1UVXzVrwAWB8RGwAk3Uj6KazS\ncA/gsOLy4aTf0zSbmLZu3TfMf/7zdP1hh8EZZ8DHP177lm9bWysfkdnrVBPus0m/VD5oM/C+sjaX\nA38n6feAg0m/PP86kpYDywE6OztrrdVsbLZtg3/4h6EwX1dslxx6KJx+OnziE/Drvw4nnOChB8tG\nvf6Tzwe+ExH/Q1I38D1J74qIfXaLR8Q1wDUAXV1d/n0/a4zt2+Huu1OQ33UXPPJIuv7gg1OYf+xj\nKcxPPNFhbtmq5j97CzC3ZH5OcV2pTwKLACKiT9J0YCawtR5Fmo3q2WeHwry3Fx5+OB0RctBBsHAh\nXHAB9PRAV1caGzfbD1QT7quB+ZKOJYX6UuCCsjYbgbOA70g6DpgObKtnoWavee45WLVqKMwffDCF\n+fTpKcyvvDKF+cknp8PkzPZDFcM9IgYkrQBuJx3m+O2IWCvpCqA/IlYCFwP/S9JnSTtXl0U06qtd\ntt/ZsQPuuWcozH/2s/RFmGnT4NRT4UtfSmG+YEG6zsxQqzK4q6sr/BuqNqydO/cN8zVrUpi3t0N3\ndxov7+mB970vba2b7UckrYmIrkrtvDfJWm/XLrj33qEw7+9P5x+ZOhVOOQUuuyyF+SmnpMMOzawi\nh7s13wsvwH33DYX56tXpm5pTp6ahlUsvTWHe3Z12ippZzRzu1ngvvgh9fUNh/tOfprP6TZmSdnp+\n7nMpzE89NR2uaGbj5nC3+nv55X3D/IEH0tkA29rS4YgXX5zCfOFCOOSQVldrliWHu43f7t1w//1D\n3wC9//503QEHwEknwUUXpZ2gCxemr/ibWcM53K12u3enoZXBMO/rS1vrBxwA730vrFiRwvy00+Dw\nw1tdrdl+yeFule3Zk3Z6Dob5ffelU9ZK6Xwsn/lMCvPTT4cZM1pdrZnhcLfhvPJKOhxxMMzvvTft\nFAV4z3tg+fKhMD/iiJaWambDc7hbOgxxzZqhML/nnnS4IsDxx8MnP5nC/Iwz0nnJzWzCc7jvjwYG\n0lf4B8N81ar0RSKAd74Tli0bCvOOjlZWamZj5HDfH+zdCw89NHQK3FWr0k/JARx3HHz0oynMzzwT\n3vCG1tZqZnXhcM/Bq6+mXxfauHFo2rRp6PIvfpFOvgXwtrfB+ecPhflRR7W2djNrCIf7ZLBr175h\nXR7gmzalI1pKHXwwHHMMzJ2bvgV62mnpi0NHH92Sh2BmzeVwb7W9e+HJJ18f3KUB/swz+97mgANg\n9mzo7EzBfe656XLpNGOGf0DZbD/mcG+kiDQcUj5MUjpt2ZICvtSMGUMhfeqprw/uo4/2z8OZ2aic\nEOOxZ08K5+HGuQennTv3vc2UKWmopLMzjXl3dg7ND172V/TNbJwc7iOJSD+0PNJOyo0b03BK+Y+d\nzJyZQnr+fDjrrH1Du7MT3vjGdAItM7MG2n/D/eWXR99JuXFj+op9qWnThsL6Ax/Yd6hk7tw0+fzj\nZjYB5Bnuwx0aWB7gW7e+/nZHHZWC+vjj4UMfen14d3R4J6WZTQqTM9x37Rp9J+XmzcMfGjgY1Cee\n+PqdlLNn+8eVzSwbky/cv/rV9DNspQYPDZw7N/1M23nn+dBAM9uvTb5wP/NMuOoqHxpoZjaKyZeI\n3d1pMjOzER3Q6gLMzKz+HO5mZhlyuJuZZcjhbmaWIYe7mVkz9fWlI/76+hq6msl3tIyZ2WTV15fO\nObVnD7S3wx13NOzoP2+5m5k1S29vCva9e9Pf3t6GrcrhbmbWLD09aYu9rS397elp2Ko8LGNm1izd\n3Wkoprc3BXsDv5DpcDez8enra0pYZaNJ37J3uJvZ2DVxB6HVxmPuZjZ2TdxBaLWpKtwlLZL0mKT1\nki4ZZvmfSnqwmB6X9Fz9SzWzCaeJOwitNhWHZSS1AVcDZwObgdWSVkbEusE2EfHZkva/B7y3AbWa\n2UTTxB2EVptqxtwXAOsjYgOApBuBJcC6EdqfD3yxPuWZ2YTn03BPSNUMy8wGNpXMby6uex1JxwDH\nAneOsHy5pH5J/du2bau1VjMzq1K9d6guBW6JiL3DLYyIayKiKyK6Ojo66rxqMzMbVE24bwHmlszP\nKa4bzlLg++MtyszMxqeacF8NzJd0rKR2UoCvLG8k6e3ArwGNPdWZmZlVVDHcI2IAWAHcDjwK3BwR\nayVdIWlxSdOlwI0REY0p1czMqlXVN1Qj4jbgtrLrvlA2f3n9yjIzs/HwN1TNzDLkcDcr1aRfyTFr\nNJ84zGyQT4JlGfGWu9kgnwTLMuJwNxvkk2BZRjwsYzbIJ8GyjDjczUr5JFiWCQ/LmJllyOFuZpYh\nh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5ll\nyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZm\nGXK4566vD666Kv01s/3GlFYXYA3U1wdnnQV79kB7O9xxB3R3t7oqM2sCb7nnrLc3Bfvevelvb2+r\nKzKzJnG456ynJ22xt7Wlvz09ra7IzJqkqnCXtEjSY5LWS7pkhDa/LWmdpLWSbqhvmTYm3d1pKObK\nKz0kY7afqTjmLqkNuBo4G9gMrJa0MiLWlbSZD1wKLIyIZyW9oVEFW426ux3qZvuharbcFwDrI2JD\nROwBbgSWlLX5FHB1RDwLEBFb61ummZnVoppwnw1sKpnfXFxX6q3AWyXdK+l+SYvqVaCZmdWuXodC\nTgHmAz3AHOBuScdHxHOljSQtB5YDdHZ21mnVZmZWrpot9y3A3JL5OcV1pTYDKyPilYj4Z+BxUtjv\nIyKuiYiuiOjq6OgYa81mZlZBNeG+Gpgv6VhJ7cBSYGVZmx+SttqRNJM0TLOhjnWamVkNKoZ7RAwA\nK4DbgUeBmyNiraQrJC0umt0ObJe0DrgL+E8Rsb1RRZuZ2egUES1ZcVdXV/T397dk3WZmk5WkNRHR\nVamdv6FqZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc\n7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYh\nh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5ll\nyOFuZpYhh7uZWYYc7mZmGXK4m5llqKpwl7RI0mOS1ku6ZJjlyyRtk/RgMV1Y/1LNzKxaUyo1kNQG\nXA2cDWwGVktaGRHrypreFBErGlCjmZnVqJot9wXA+ojYEBF7gBuBJY0ty8zMxqOacJ8NbCqZ31xc\nV+5cSQ9LukXS3OHuSNJySf2S+rdt2zaGcs3MrBr12qH6t8C8iHg38BPguuEaRcQ1EdEVEV0dHR11\nWrWZmZWrJty3AKVb4nOK614TEdsjYncxey1wUn3KMzOzsagm3FcD8yUdK6kdWAqsLG0gaVbJ7GLg\n0fqVaGZmtap4tExEDEhaAdwOtAHfjoi1kq4A+iNiJfD7khYDA8AzwLIG1mxmZhUoIlqy4q6urujv\n72/Jus3MJitJayKiq1I7f0PVzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPL\nkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3M\nMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDncz\nsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMlRVuEtaJOkxSeslXTJKu3MlhaSu+pVoZma1qhju\nktqAq4EPAu8Azpf0jmHaHQpcBDxQ7yLNzKw21Wy5LwDWR8SGiNgD3AgsGabdlcAfAy/XsT4zMxuD\nasJ9NrCpZH5zcd1rJJ0IzI2IH412R5KWS+qX1L9t27aaizUzs+qMe4eqpAOArwEXV2obEddERFdE\ndHV0dIx31WZmNoJqwn0LMLdkfk5x3aBDgXcBvZKeAE4BVnqnqplZ61QT7quB+ZKOldQOLAVWDi6M\niB0RMTMi5kXEPOB+YHFE9DekYjMzq6hiuEfEALACuB14FLg5ItZKukLS4kYXaGZmtZtSTaOIuA24\nrey6L4zQtmf8ZZmZ2Xj4G6pmZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWockX7n19\ncNVV6a+ZmQ2rqi8xTRh9fXDWWbBnD7S3wx13QHd3q6syM5twJteWe29vCva9e9Pf3t5WV2RmNiFN\nrnDv6Ulb7G1t6W9PT6srMjObkCbXsEx3dxqK6e1Nwe4hGTOzYU2ucIcU6A51M7NRTa5hGTMzq4rD\n3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQ4qI1qxY2gb8yxhvPhN4uo7l1Ivrqo3rqt1Erc111WY8\ndR0TER2VGrUs3MdDUn9EdLW6jnKuqzauq3YTtTbXVZtm1OVhGTOzDDnczcwyNFnD/ZpWFzAC11Ub\n11W7iVqb66pNw+ualGPuZmY2usm65W5mZqNwuJuZZWhCh7ukRZIek7Re0iXDLJ8m6aZi+QOS5k2Q\nupZJ2ibpwWK6sEl1fVvSVkmPjLBckr5e1P2wpBMnSF09knaU9NcXmlDTXEl3SVonaa2ki4Zp0/T+\nqrKuVvTXdEk/lfRQUdeXhmnT9NdjlXW15PVYrLtN0s8k3TrMssb2V0RMyAloA34JvAloBx4C3lHW\n5neBbxWXlwI3TZC6lgF/3oI+OwM4EXhkhOW/BfwYEHAK8MAEqasHuLXJfTULOLG4fCjw+DDPY9P7\nq8q6WtFfAg4pLk8FHgBOKWvTitdjNXW15PVYrPsPgRuGe74a3V8Tect9AbA+IjZExB7gRmBJWZsl\nwHXF5VuAsyRpAtTVEhFxN/DMKE2WAN+N5H5ghqRZE6CupouIJyPiH4vLO4FHgdllzZreX1XW1XRF\nH+wqZqcWU/nRGE1/PVZZV0tImgN8CLh2hCYN7a+JHO6zgU0l85t5/T/5a20iYgDYARw5AeoCOLf4\nKH+LpLkNrqla1dbeCt3FR+sfS3pnM1dcfBx+L2mrr1RL+2uUuqAF/VUMMTwIbAV+EhEj9lcTX4/V\n1AWteT3+T+BzwKsjLG9of03kcJ/M/haYFxHvBn7C0LuzDe8fSefLeA/wDeCHzVqxpEOAvwb+ICKe\nb9Z6K6lQV0v6KyL2RsQJwBxggaR3NWO9lVRRV9Nfj5LOAbZGxJpGr2skEznctwCl77BziuuGbSNp\nCnA4sL3VdUXE9ojYXcxeC5zU4JqqVU2fNl1EPD/40ToibgOmSprZ6PVKmkoK0L+KiL8ZpklL+qtS\nXa3qr5L1PwfcBSwqW9SK12PFulr0elwILJb0BGno9jckXV/WpqH9NZHDfTUwX9KxktpJOxxWlrVZ\nCfxOcfk84M4o9k60sq6ycdnFpHHTiWAl8LHiKJBTgB0R8WSri5J01OBYo6QFpP/LhoZCsb7/DTwa\nEV8boVnT+6uaulrUXx2SZhSXDwTOBn5e1qzpr8dq6mrF6zEiLo2IORExj5QRd0bER8qaNbS/ptTr\njuotIgYkrQBuJx2h8u2IWCvpCqA/IlaSXgTfk7SetMNu6QSp6/clLQYGirqWNbouAEnfJx1JMVPS\nZuCLpB1MRMS3gNtIR4CsB14EPj5B6joP+IykAeAlYGkT3qQXAh8F/qkYrwX4PNBZUlcr+quaulrR\nX7OA6yS1kd5Mbo6IW1v9eqyyrpa8HofTzP7y6QfMzDI0kYdlzMxsjBzuZmYZcribmWXI4W5mliGH\nu5lZhhzuZmYZcribmWXo/wOVwDWLUOaGcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fbcd7beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhhzuZmYZcribmWXI4W5mlqH/D4EOMVPhN4D9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fbc95a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tuning starting...\n",
      "Epoch 1/10\n",
      "416/416 [==============================] - 244s - loss: 0.8088 - acc: 0.7606 - val_loss: 0.5355 - val_acc: 0.8273\n",
      "Epoch 2/10\n",
      "416/416 [==============================] - 243s - loss: 0.7496 - acc: 0.7693 - val_loss: 0.4978 - val_acc: 0.8369\n",
      "Epoch 3/10\n",
      "416/416 [==============================] - 243s - loss: 0.7082 - acc: 0.7836 - val_loss: 0.5010 - val_acc: 0.8386\n",
      "Epoch 4/10\n",
      "416/416 [==============================] - 243s - loss: 0.6937 - acc: 0.7861 - val_loss: 0.4853 - val_acc: 0.8474\n",
      "Epoch 5/10\n",
      "416/416 [==============================] - 243s - loss: 0.6646 - acc: 0.7986 - val_loss: 0.4670 - val_acc: 0.8510\n",
      "Epoch 6/10\n",
      "416/416 [==============================] - 243s - loss: 0.6272 - acc: 0.8069 - val_loss: 0.4545 - val_acc: 0.8494\n",
      "Epoch 7/10\n",
      "416/416 [==============================] - 243s - loss: 0.5950 - acc: 0.8104 - val_loss: 0.4710 - val_acc: 0.8494\n",
      "Epoch 8/10\n",
      "416/416 [==============================] - 243s - loss: 0.6117 - acc: 0.8115 - val_loss: 0.4699 - val_acc: 0.8490\n",
      "Epoch 9/10\n",
      "416/416 [==============================] - 243s - loss: 0.6008 - acc: 0.8083 - val_loss: 0.4778 - val_acc: 0.8510\n",
      "Epoch 10/10\n",
      "416/416 [==============================] - 243s - loss: 0.5655 - acc: 0.8234 - val_loss: 0.4544 - val_acc: 0.8550\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD11dxcZp3D39AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fbb894f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fbb7ccf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# A little plot helper allowing us to visualise the result\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "# A continuously decreasing learning rate schedule\n",
    "def continuous_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    lr = initial_lrate * (0.1 ** int(epoch / 10))\n",
    "    return lr\n",
    "\n",
    "# Another stepped decreasing learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5.0\n",
    "    lr = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "# Use transfer learning and fine-tuning to train a network on a given dataset\n",
    "def train():\n",
    "    no_of_train_samples = len(train_generator.filenames)\n",
    "    no_of_valid_samples = len(valid_generator.filenames)\n",
    "\n",
    "    # We calculate the number of itrations ourselves as there are a small bug in predict_generator\n",
    "    # and fit_generator when working on batches when the number of samples are not divisible\n",
    "    # by the batch size\n",
    "    no_of_train_iterations = int(math.ceil(no_of_train_samples / BATCH_SIZE))  \n",
    "    no_of_valid_iterations = int(math.ceil(no_of_valid_samples / BATCH_SIZE))*3 \n",
    "\n",
    "    print(\"transfer learning starting...\")\n",
    "    use_transfer_learning()\n",
    "    history_tl = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=no_of_train_iterations,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=no_of_valid_iterations,\n",
    "        verbose=1)    \n",
    "    plot_training(history_tl)\n",
    "\n",
    "    print(\"fine-tuning starting...\")\n",
    "    use_finetuning(lr=7e-4, decay=1e-5)\n",
    "    history_ft = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=no_of_train_iterations,\n",
    "        epochs=2*EPOCHS,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=no_of_valid_iterations,\n",
    "        verbose=1)    \n",
    "    plot_training(history_ft)\n",
    "\n",
    "    \n",
    "# Lets train away\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836/836 [00:06<00:00, 131.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88.3971%\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image    \n",
    "from sklearn.datasets import load_files  \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), NO_OF_CLASSES)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(WIDTH, HEIGHT))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (WIDTH, HEIGHT, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, WIDTH, HEIGHT, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "test_files, test_targets = load_dataset(TEST_DATA_DIR)\n",
    "# Pre-process the data for Keras\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "\n",
    "# Get index of predicted dog breed for each image in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# Report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/Alfie-JackRussel.jpg\n",
      "[[  2.10856001e-07   4.12815071e-09   1.90427855e-07   9.59704994e-05\n",
      "    5.85709415e-07   1.85751844e-06   6.47896959e-04   3.31392020e-01\n",
      "    4.43459278e-08   2.58236687e-04   3.76326352e-06   3.02937024e-05\n",
      "    3.52123237e-07   2.55432060e-05   1.27998305e-06   2.39659494e-04\n",
      "    2.35434800e-06   7.13063628e-07   1.23907671e-06   5.04377624e-08\n",
      "    7.74832145e-08   9.61040136e-09   2.81406081e-08   2.72992452e-06\n",
      "    7.30000504e-09   1.52686468e-08   1.01352464e-08   3.08194039e-08\n",
      "    9.83038626e-06   2.43137742e-06   1.71358188e-05   3.02612875e-06\n",
      "    2.35208915e-07   1.96923083e-05   2.85520425e-08   3.67433330e-07\n",
      "    1.36351897e-04   6.20509013e-07   1.11981630e-02   3.15738696e-04\n",
      "    6.58528552e-06   1.34649190e-05   1.88683043e-03   1.25839142e-04\n",
      "    9.59311001e-06   1.80429680e-07   1.98215889e-06   1.93564156e-05\n",
      "    1.00546379e-06   2.84705147e-05   2.29722616e-07   3.94548977e-07\n",
      "    3.44684636e-08   1.17195739e-07   2.65699125e-08   4.63617170e-07\n",
      "    4.67756727e-05   7.92540777e-06   6.32368597e-07   1.37014717e-06\n",
      "    1.83731554e-08   1.41773398e-06   3.06259994e-06   3.94983957e-08\n",
      "    6.37851599e-06   8.23059754e-09   4.42394779e-08   2.67663545e-08\n",
      "    4.69897032e-07   2.13761950e-06   5.08608666e-09   5.99022133e-06\n",
      "    4.70936016e-07   1.18555491e-07   1.29519351e-04   7.62325385e-07\n",
      "    7.00704494e-10   7.41024269e-05   3.23433887e-05   1.68183633e-05\n",
      "    2.19708818e-04   2.74096487e-06   2.74278477e-06   1.96449150e-06\n",
      "    2.83080567e-06   7.40224548e-09   2.57912006e-06   2.71185518e-09\n",
      "    6.87344482e-06   1.54823487e-04   4.61635295e-07   7.90481813e-09\n",
      "    5.23674316e-07   7.43740770e-07   4.09780523e-06   4.30429151e-04\n",
      "    1.83667726e-05   3.27243233e-09   2.76272971e-07   1.49773109e-06\n",
      "    2.01939611e-06   2.83836403e-06   1.73006379e-06   5.07535447e-07\n",
      "    5.91640003e-07   5.25108646e-07   4.32697525e-05   6.74071862e-06\n",
      "    6.19990530e-08   1.42964182e-05   7.65470031e-06   8.48067316e-07\n",
      "    3.64458543e-07   6.20866274e-08   4.57897578e-08   5.81158698e-01\n",
      "    1.01513869e-07   1.07886315e-07   5.36541211e-06   6.44663558e-08\n",
      "    9.17473244e-06   1.27422726e-02   3.75789462e-08   3.92598452e-08\n",
      "    1.41997390e-07   1.65367157e-06   2.70260125e-06   5.83081469e-02\n",
      "    6.55940511e-08   1.80668076e-06   9.17577339e-08   1.40115731e-07\n",
      "    3.25785822e-06]]\n",
      "Parson_russell_terrier\n",
      "images/Alfie-JackRussel_1.jpg\n",
      "[[  1.07390042e-05   1.14370232e-04   2.86901166e-04   5.02921524e-04\n",
      "    6.66551350e-04   3.62163919e-05   1.05103981e-02   3.67144346e-02\n",
      "    9.49450168e-07   2.40091719e-02   4.42399411e-03   5.65826427e-04\n",
      "    4.27864616e-05   5.13347739e-04   1.12801732e-04   8.45978328e-04\n",
      "    6.22072912e-05   2.12953333e-03   6.02621003e-05   1.70011923e-03\n",
      "    2.49323821e-05   1.54618920e-05   2.71982731e-06   3.83991392e-05\n",
      "    1.31683541e-04   8.29083365e-06   5.98811603e-04   4.13235139e-05\n",
      "    1.65278456e-04   2.22613162e-04   1.36533915e-03   5.41908608e-04\n",
      "    5.49010610e-06   7.15900853e-04   5.08714402e-06   8.56980769e-05\n",
      "    7.58600218e-05   7.26278813e-05   1.43143442e-02   1.22135901e-03\n",
      "    1.59015658e-03   2.74135557e-04   3.88239063e-02   3.06171807e-03\n",
      "    8.45960632e-04   4.29135298e-06   7.05844432e-04   5.66895073e-03\n",
      "    2.20195646e-03   5.82801132e-03   1.66903737e-06   5.19838432e-06\n",
      "    3.20206527e-05   7.82713323e-06   1.09645634e-05   2.73695262e-03\n",
      "    1.11130299e-03   5.37004453e-05   3.83646274e-03   1.57823262e-04\n",
      "    2.86289869e-05   2.82588939e-04   5.90457921e-06   1.59320607e-05\n",
      "    7.47881597e-04   1.94959489e-06   4.02093465e-05   5.53519494e-05\n",
      "    1.64186917e-04   2.41316147e-02   4.42336750e-04   9.79427350e-05\n",
      "    1.66482569e-05   2.53127102e-04   3.19097046e-04   3.03434586e-04\n",
      "    1.86667864e-06   3.67859341e-02   9.22997569e-05   4.23231075e-04\n",
      "    5.10987878e-01   6.14636738e-05   1.02359685e-03   4.21002478e-04\n",
      "    7.88873149e-06   5.56411123e-06   2.71110935e-03   1.32382490e-06\n",
      "    4.40720672e-04   3.15873437e-02   3.94099734e-05   6.99705481e-07\n",
      "    3.66289925e-04   6.40690705e-05   1.02115482e-04   4.46791388e-02\n",
      "    2.54206971e-04   7.00557507e-07   1.40512275e-05   9.08265065e-05\n",
      "    5.67720126e-05   1.03877699e-02   5.32088394e-04   1.52379886e-04\n",
      "    6.16572943e-05   8.69173527e-06   3.54996650e-04   1.87235826e-03\n",
      "    6.16881152e-05   1.55909965e-03   1.36326460e-04   3.08744748e-05\n",
      "    6.68738403e-06   1.30244416e-05   6.12971644e-06   4.16087769e-02\n",
      "    2.51069450e-05   4.74949920e-05   6.32291049e-05   9.02253436e-04\n",
      "    3.70787433e-03   1.24303289e-02   9.49959576e-06   1.36720439e-04\n",
      "    7.00524424e-06   7.49950686e-06   4.15402232e-04   9.74156335e-02\n",
      "    4.71011845e-06   4.13805992e-06   1.74259287e-06   8.82809691e-04\n",
      "    9.82003112e-05]]\n",
      "Greyhound\n",
      "images/Trex-YorkshireTerrier.jpg\n",
      "[[  8.32633589e-08   1.20056542e-09   1.21916992e-08   1.31025075e-08\n",
      "    5.88652904e-10   6.59609922e-09   2.03617101e-09   4.05302778e-08\n",
      "    1.28213129e-09   3.67677416e-10   5.31908370e-07   1.19872141e-07\n",
      "    3.04780062e-03   2.75977374e-08   1.64907987e-09   4.18867518e-09\n",
      "    1.11572604e-06   3.19406098e-07   8.22119595e-10   5.26760324e-09\n",
      "    3.45107622e-08   1.03185815e-08   1.46444123e-07   5.67282825e-08\n",
      "    3.27831118e-09   1.49315926e-09   3.31311045e-09   6.15706552e-09\n",
      "    5.74236658e-09   8.24909652e-09   3.02420117e-10   2.45908289e-08\n",
      "    4.28416458e-09   2.06276898e-08   1.85986249e-09   4.14501393e-08\n",
      "    3.19563469e-08   9.86859803e-08   2.05369144e-09   1.42519099e-08\n",
      "    3.94683308e-09   1.08628628e-05   1.97342018e-08   1.62646483e-08\n",
      "    9.48896695e-09   6.49967376e-07   1.92007965e-09   9.56153031e-07\n",
      "    5.95347374e-05   2.42495912e-09   9.63343449e-09   6.80184886e-09\n",
      "    8.80970408e-09   8.60359162e-09   1.50516888e-09   3.02478014e-07\n",
      "    5.04101338e-09   1.86602847e-06   9.51067420e-07   6.15175999e-09\n",
      "    4.62310936e-08   1.42079337e-09   3.89031474e-09   2.10103025e-07\n",
      "    2.83921118e-08   8.37723835e-10   3.49090392e-08   1.70310910e-09\n",
      "    2.46139990e-07   1.45558079e-06   6.59635058e-09   5.07867348e-08\n",
      "    6.90345914e-08   4.39708270e-10   9.70859730e-08   7.17544646e-09\n",
      "    1.11278453e-08   9.12642495e-09   5.36052258e-10   1.19009691e-08\n",
      "    6.51132093e-10   6.59501779e-07   9.39277367e-09   4.63105252e-08\n",
      "    3.47672224e-09   4.04121536e-09   5.37971978e-09   1.06780507e-09\n",
      "    6.93444191e-09   1.26947839e-08   1.82311126e-08   6.64053772e-08\n",
      "    6.72588829e-09   2.47719782e-08   4.72784867e-10   4.21587831e-09\n",
      "    2.86523694e-08   8.18357372e-13   6.16891853e-08   1.18107880e-06\n",
      "    9.21131686e-08   4.58664005e-07   2.13781493e-10   1.17047516e-09\n",
      "    2.62928651e-10   2.25046690e-10   8.83706832e-07   6.44639853e-09\n",
      "    3.08254283e-10   7.69222686e-10   8.04625088e-05   2.35242439e-08\n",
      "    1.06693836e-08   7.58612995e-09   7.40655359e-09   6.55570875e-10\n",
      "    1.67271863e-09   4.31641745e-08   4.05135872e-08   1.92823478e-07\n",
      "    3.35481243e-09   1.29943949e-08   4.41007231e-08   3.52017482e-09\n",
      "    2.66427236e-09   1.83022195e-12   8.25337946e-01   5.60745950e-10\n",
      "    1.30002387e-09   8.96493813e-09   1.00675237e-08   1.74035094e-07\n",
      "    1.71449259e-01]]\n",
      "Silky_terrier\n",
      "images/Trex-YorkshireTerrier_1.jpg\n",
      "[[  1.09867040e-06   1.46131409e-08   1.50637186e-06   4.26909930e-09\n",
      "    5.33066213e-09   1.11011138e-08   6.23255829e-08   1.43646923e-06\n",
      "    1.37809266e-08   4.78757034e-09   2.13499970e-06   1.90594292e-07\n",
      "    2.86193332e-04   5.27026645e-09   6.71165079e-09   1.97230762e-07\n",
      "    1.73022579e-06   1.76409486e-07   4.23718616e-09   5.66446556e-10\n",
      "    1.19694166e-09   9.52324997e-10   9.26384089e-08   7.44352838e-06\n",
      "    2.07042902e-07   3.63175978e-08   1.66877840e-07   3.62603799e-07\n",
      "    1.51159423e-08   9.12814630e-06   4.58047433e-10   8.51019308e-08\n",
      "    1.50197224e-08   1.90996772e-07   4.11251211e-09   5.36988466e-07\n",
      "    3.00745988e-08   1.43305751e-05   8.87451168e-10   3.12714576e-07\n",
      "    5.41652469e-07   4.33206014e-06   3.40935324e-09   1.05603306e-06\n",
      "    3.54332808e-09   2.57770553e-05   4.27919389e-08   4.16534704e-06\n",
      "    4.42182354e-04   6.73191138e-08   1.08708376e-08   1.41396264e-08\n",
      "    1.49286268e-06   1.78620208e-09   1.28445494e-08   1.36309536e-04\n",
      "    7.41977857e-08   1.19829252e-04   9.96213316e-07   4.65083929e-07\n",
      "    2.65811821e-07   7.14745996e-09   1.93411709e-09   3.46178203e-05\n",
      "    1.41442470e-07   3.78098619e-09   2.27706245e-08   5.18456211e-09\n",
      "    1.53392676e-07   2.41982093e-06   4.35389769e-09   8.71538532e-07\n",
      "    9.05819377e-07   6.90401958e-10   1.51523778e-07   1.30366544e-07\n",
      "    2.66704632e-07   1.16210055e-08   3.22033444e-09   2.66955897e-08\n",
      "    7.57960306e-10   7.07898653e-05   7.98092759e-10   1.21833557e-08\n",
      "    4.12228163e-09   1.41027073e-07   2.53764256e-07   1.01946531e-08\n",
      "    1.48114196e-08   2.24578276e-08   5.76062469e-08   8.97543302e-08\n",
      "    9.73347127e-08   5.10928935e-08   4.04119099e-10   5.69106788e-08\n",
      "    1.75857951e-06   1.71983087e-11   3.07800224e-06   6.89617955e-05\n",
      "    2.12191549e-06   9.38549590e-07   1.29596689e-08   1.31259526e-07\n",
      "    2.87849868e-08   1.01257358e-09   3.27954367e-05   2.37118569e-09\n",
      "    1.34405875e-10   1.76679360e-09   1.18992402e-05   1.92747549e-07\n",
      "    2.49913623e-09   6.45957243e-08   8.74559980e-09   2.64862132e-09\n",
      "    5.00677935e-08   4.39384085e-09   6.20217975e-07   5.62822109e-08\n",
      "    1.57321068e-07   2.23149272e-07   5.18412016e-08   3.47641240e-08\n",
      "    1.81690567e-07   6.96480373e-11   1.27947867e-01   1.02167996e-09\n",
      "    2.57187711e-08   7.32161975e-09   1.12468122e-07   3.86668191e-08\n",
      "    8.70751917e-01]]\n",
      "Yorkshire_terrier\n",
      "images/John.jpg\n",
      "[[  1.16445525e-02   1.62715167e-02   1.75767543e-03   2.72807456e-03\n",
      "    6.24503882e-04   1.24900113e-03   2.96996091e-04   3.66653112e-04\n",
      "    5.77413067e-02   4.17532120e-03   1.50037510e-02   1.16925137e-02\n",
      "    3.33607234e-02   1.45484810e-03   2.07263255e-03   6.76483323e-04\n",
      "    1.43718785e-02   2.71287523e-02   9.77806863e-04   2.21934672e-02\n",
      "    8.49133730e-03   4.78540249e-02   3.51191475e-03   1.38954772e-03\n",
      "    4.57494333e-03   1.86944497e-03   6.65143924e-03   1.04448164e-03\n",
      "    6.17196376e-04   2.25222786e-03   2.73896591e-03   7.03876896e-04\n",
      "    4.99080447e-03   9.01306630e-04   2.55027786e-02   1.02276411e-02\n",
      "    1.53906620e-03   1.62222441e-02   1.55408378e-03   7.55767920e-04\n",
      "    3.42343003e-03   1.40309092e-02   2.87716743e-03   1.02429511e-03\n",
      "    1.07143978e-02   1.27523672e-02   2.29706103e-03   6.65437710e-03\n",
      "    1.41712902e-02   4.03697276e-03   2.19431170e-03   8.15879926e-03\n",
      "    7.61784473e-03   6.83549838e-03   9.73548554e-03   5.10398857e-02\n",
      "    3.38411221e-04   7.95110222e-03   3.75215104e-03   3.59303807e-03\n",
      "    2.49848366e-02   4.26973635e-03   3.55956634e-03   1.98305063e-02\n",
      "    7.09017389e-04   1.67042650e-02   3.08969524e-03   1.38468817e-02\n",
      "    7.34808575e-03   2.95583718e-03   3.30009721e-02   1.15476651e-04\n",
      "    2.52556731e-03   1.79898017e-03   1.11308666e-02   5.28752198e-03\n",
      "    1.62174962e-02   8.39781773e-04   1.24989951e-03   3.63408646e-04\n",
      "    9.33752686e-04   9.64746065e-03   1.91383238e-03   1.85753368e-02\n",
      "    9.37229767e-03   1.81057137e-02   3.94076481e-03   8.69868230e-03\n",
      "    5.36827929e-03   2.20220973e-04   1.67915109e-03   1.98492929e-02\n",
      "    9.19309503e-04   3.98351159e-03   1.31151592e-03   6.79719320e-04\n",
      "    4.38827369e-03   2.80627026e-03   5.71663445e-03   1.04460660e-02\n",
      "    6.33082469e-04   2.43387860e-03   8.58674478e-03   8.46544164e-04\n",
      "    1.45353063e-03   1.90494990e-03   2.33677728e-03   9.40200640e-04\n",
      "    6.40806276e-03   2.63446989e-03   1.10493554e-02   7.19875516e-03\n",
      "    4.75168414e-03   1.51466867e-02   4.52121207e-03   2.86187686e-04\n",
      "    6.70397794e-03   6.05424726e-03   9.45702847e-03   3.07382480e-03\n",
      "    1.66743819e-03   8.82786626e-05   1.72924751e-03   1.43054547e-03\n",
      "    5.90260141e-03   1.97763584e-04   2.42863502e-02   5.71987126e-04\n",
      "    3.91006051e-03   5.27426135e-03   3.72516760e-03   4.91907867e-03\n",
      "    9.11109895e-03]]\n",
      "American_water_spaniel\n",
      "images/Sue.jpg\n",
      "[[ 0.01533967  0.00321233  0.01317651  0.00305358  0.00131019  0.00534735\n",
      "   0.01301352  0.0064801   0.00313652  0.00855706  0.00261528  0.00352739\n",
      "   0.00817095  0.0011354   0.00317107  0.01092225  0.0029322   0.00445007\n",
      "   0.01283393  0.00497388  0.0046076   0.00170978  0.00229225  0.00662607\n",
      "   0.01275145  0.00693085  0.01571983  0.00451451  0.00257579  0.01730869\n",
      "   0.00163758  0.00321283  0.00591367  0.00578091  0.00303907  0.00482818\n",
      "   0.00382136  0.04064175  0.00303927  0.0054076   0.01364558  0.00397592\n",
      "   0.00587627  0.01148691  0.00387518  0.00565872  0.02543022  0.00551033\n",
      "   0.01891398  0.0152418   0.00380237  0.00070431  0.00211124  0.00078303\n",
      "   0.00579148  0.01815654  0.00462203  0.00205462  0.00411448  0.00742497\n",
      "   0.00179896  0.00160838  0.00132673  0.00476311  0.0027762   0.00212719\n",
      "   0.00814809  0.01532734  0.00378456  0.00833903  0.00448463  0.00414106\n",
      "   0.00322539  0.02625839  0.00523117  0.01223456  0.00311009  0.01342466\n",
      "   0.00377454  0.00480569  0.02064979  0.00507011  0.00370452  0.004573\n",
      "   0.00148183  0.0056579   0.01946067  0.00482804  0.00343662  0.01062645\n",
      "   0.01447434  0.00197577  0.02730456  0.00158252  0.0022484   0.01414097\n",
      "   0.01117346  0.00065248  0.00449336  0.0068717   0.01006976  0.00274645\n",
      "   0.0078021   0.00117204  0.0077125   0.00759952  0.01395589  0.00284767\n",
      "   0.00167031  0.00185822  0.01154828  0.01296119  0.0038966   0.00468397\n",
      "   0.01563286  0.00264693  0.01106345  0.00296719  0.00162817  0.00924257\n",
      "   0.04461091  0.0034812   0.02468441  0.0194367   0.00553751  0.0018512\n",
      "   0.01002484  0.00209944  0.00194226  0.00123707  0.00202082  0.00813849\n",
      "   0.00723494]]\n",
      "Plott\n",
      "images/Sue1.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00671327  0.0115557   0.00619163  0.01370979  0.00309523  0.00231925\n",
      "   0.00462362  0.0042687   0.00287178  0.00224115  0.00545279  0.00841064\n",
      "   0.00610415  0.00409055  0.01161014  0.00379717  0.00647594  0.00281616\n",
      "   0.0027668   0.00873152  0.00828786  0.0052069   0.00259724  0.00402183\n",
      "   0.00227354  0.00495422  0.00690933  0.00158074  0.00258812  0.0009346\n",
      "   0.00552813  0.01864189  0.00788027  0.00585171  0.00304227  0.00841685\n",
      "   0.00483042  0.01274572  0.00854075  0.01641008  0.00374635  0.00144201\n",
      "   0.01693078  0.00476879  0.03048354  0.02537743  0.00410515  0.02213579\n",
      "   0.09004343  0.00311478  0.00217735  0.00055572  0.00202264  0.01045584\n",
      "   0.00256934  0.03361588  0.01013339  0.00066066  0.00915125  0.00412262\n",
      "   0.00281737  0.00299463  0.00334446  0.02568439  0.00219486  0.00166131\n",
      "   0.01097341  0.00276869  0.01837747  0.0116198   0.00578512  0.00358469\n",
      "   0.00111362  0.00533647  0.00194663  0.0027325   0.00125451  0.01139002\n",
      "   0.00272526  0.00112355  0.00825494  0.00947077  0.00504314  0.02759961\n",
      "   0.00640175  0.03342182  0.00501364  0.00541181  0.00259685  0.00766288\n",
      "   0.01440839  0.00087689  0.00820252  0.0046836   0.00170868  0.00113637\n",
      "   0.00530688  0.00029261  0.00656516  0.0074877   0.00610603  0.00695103\n",
      "   0.00206118  0.0007934   0.00218902  0.00248752  0.00201645  0.0028278\n",
      "   0.00187661  0.00904802  0.00386373  0.00839117  0.00333033  0.00265012\n",
      "   0.0331939   0.00221004  0.00561948  0.01584373  0.00216526  0.00593411\n",
      "   0.00541952  0.00239359  0.00586311  0.01174502  0.00333407  0.00099225\n",
      "   0.00983689  0.00274708  0.00067675  0.0052737   0.00157529  0.01154276\n",
      "   0.01136513]]\n",
      "Chinese_crested\n",
      "images/Oscar.jpg\n",
      "[[ 0.00758267  0.00066537  0.00550208  0.00529875  0.0019304   0.00206008\n",
      "   0.0179222   0.00420055  0.0011384   0.00431803  0.00220944  0.00618455\n",
      "   0.01559936  0.00308106  0.007944    0.00990767  0.00634966  0.00256784\n",
      "   0.00138495  0.00422348  0.00186566  0.00109554  0.0015295   0.00718837\n",
      "   0.0068343   0.00131004  0.04594335  0.00127237  0.00165244  0.00240366\n",
      "   0.00122827  0.00071141  0.00157663  0.00276029  0.00101985  0.00550259\n",
      "   0.00183665  0.00607864  0.00174633  0.00445951  0.00606507  0.00247876\n",
      "   0.004628    0.0039743   0.00581869  0.00236045  0.03692216  0.00156114\n",
      "   0.00388119  0.01894889  0.00614289  0.00081432  0.00048324  0.00387637\n",
      "   0.00195122  0.03256268  0.01203692  0.0012852   0.01024695  0.06389306\n",
      "   0.00184811  0.00045223  0.00035139  0.00115905  0.00187495  0.00087476\n",
      "   0.0396327   0.00200285  0.00166486  0.03044273  0.00317751  0.00701128\n",
      "   0.00208455  0.00254676  0.00170243  0.02520712  0.00140932  0.00455733\n",
      "   0.01302046  0.00495082  0.00454048  0.0074287   0.00244244  0.0082402\n",
      "   0.00078268  0.01985472  0.00941756  0.00291087  0.00090875  0.0064742\n",
      "   0.00318981  0.00180184  0.00469478  0.00174319  0.00436541  0.01285925\n",
      "   0.0039163   0.00032171  0.01173198  0.01338743  0.00941692  0.00304762\n",
      "   0.00186383  0.00029835  0.00524737  0.00244542  0.01358196  0.00127083\n",
      "   0.00077909  0.00121165  0.02003506  0.06321291  0.00634958  0.00378956\n",
      "   0.00179939  0.00227855  0.00278082  0.01389417  0.00114745  0.03331665\n",
      "   0.0173748   0.00243536  0.00731938  0.00231191  0.00145427  0.00063718\n",
      "   0.03273372  0.0010964   0.00197285  0.00114479  0.00165066  0.00174819\n",
      "   0.04535248]]\n",
      "Dogue_de_bordeaux\n",
      "images/Sample_CNN.png\n",
      "[[ 0.02456799  0.00386656  0.00078207  0.00590911  0.00099974  0.0060779\n",
      "   0.00146579  0.00431117  0.00975668  0.01111183  0.00088962  0.01257599\n",
      "   0.00312951  0.00066851  0.00155399  0.00205027  0.00373271  0.00565885\n",
      "   0.00018097  0.00425718  0.0043186   0.00569491  0.00172407  0.00115004\n",
      "   0.00385456  0.00469918  0.00509497  0.00044845  0.00089642  0.00248851\n",
      "   0.01401022  0.00347674  0.00839972  0.01674556  0.0141955   0.00571195\n",
      "   0.00344325  0.056934    0.00218152  0.03311727  0.16886659  0.0051415\n",
      "   0.00488784  0.01750191  0.00615348  0.01143472  0.00887934  0.01009754\n",
      "   0.0043656   0.02666708  0.00219627  0.00830284  0.00353475  0.00523935\n",
      "   0.00815535  0.00825103  0.00225692  0.0004487   0.00461404  0.01213296\n",
      "   0.002508    0.00150427  0.00451712  0.01423813  0.00287209  0.0090991\n",
      "   0.00102224  0.00365651  0.03046025  0.00276729  0.00210587  0.00129149\n",
      "   0.00071186  0.00749883  0.00185375  0.00269497  0.00156048  0.00256487\n",
      "   0.00763385  0.00086926  0.00384698  0.00466425  0.00076985  0.00491798\n",
      "   0.00367175  0.00727883  0.00143744  0.00203921  0.00202863  0.00099388\n",
      "   0.04381188  0.00482368  0.00276119  0.00055063  0.00313434  0.00901198\n",
      "   0.00066553  0.00053287  0.00749334  0.00365482  0.00443216  0.00179186\n",
      "   0.0373111   0.00056461  0.00722348  0.00085302  0.00100917  0.00090969\n",
      "   0.00059698  0.00254804  0.00185039  0.00382164  0.00053272  0.00047997\n",
      "   0.02791037  0.00080572  0.0558948   0.00276545  0.00078222  0.00101118\n",
      "   0.00203931  0.00078615  0.00917753  0.00101547  0.00136121  0.00151995\n",
      "   0.00245999  0.00172385  0.00021176  0.00217695  0.00035872  0.00189527\n",
      "   0.0014004 ]]\n",
      "Bullmastiff\n",
      "images/Square.png\n",
      "[[ 0.00443797  0.00638358  0.00069801  0.0312037   0.00318563  0.01322502\n",
      "   0.00392664  0.01708382  0.00984928  0.02105382  0.00333785  0.00172126\n",
      "   0.00196555  0.00213089  0.00607435  0.00903835  0.00154884  0.00274994\n",
      "   0.00106922  0.00451429  0.00113376  0.00561502  0.00101811  0.00602062\n",
      "   0.01125565  0.01017224  0.01506537  0.0043944   0.00036986  0.00180935\n",
      "   0.00618969  0.00355377  0.00610426  0.01955068  0.01347142  0.00281685\n",
      "   0.00352514  0.00469824  0.00497834  0.01113919  0.03829674  0.00484935\n",
      "   0.02014787  0.08246262  0.00237523  0.00351625  0.00968027  0.00454196\n",
      "   0.00360584  0.038055    0.01113007  0.01614276  0.00981321  0.00166513\n",
      "   0.00849502  0.00442922  0.00295736  0.00150538  0.00954451  0.01443495\n",
      "   0.0043169   0.00299805  0.00406707  0.00605903  0.00227935  0.01126908\n",
      "   0.0044078   0.00446315  0.00746102  0.00326181  0.00685545  0.00732059\n",
      "   0.00200764  0.01102814  0.00128332  0.00522521  0.00129832  0.01580481\n",
      "   0.02555362  0.00569472  0.01003088  0.00402703  0.00090295  0.00852985\n",
      "   0.00172844  0.00380382  0.00055967  0.00850022  0.00098821  0.00106371\n",
      "   0.00647132  0.00782286  0.00441513  0.0014022   0.00633745  0.01889965\n",
      "   0.00130795  0.00160363  0.00874565  0.00334199  0.00214892  0.00120848\n",
      "   0.04950822  0.00156863  0.02777109  0.00493013  0.00075969  0.00644363\n",
      "   0.00298857  0.00164673  0.00340845  0.00485288  0.0004889   0.00087369\n",
      "   0.00155212  0.00074796  0.02257444  0.00291054  0.00091366  0.00144389\n",
      "   0.02083324  0.00495824  0.00509083  0.01506728  0.00281605  0.00354859\n",
      "   0.00221178  0.00080944  0.00096253  0.00217639  0.00115924  0.00157672\n",
      "   0.00118264]]\n",
      "Cane_corso\n",
      "images/Galaxy.jpg\n",
      "[[  1.58958160e-03   7.41360476e-04   2.15318621e-04   6.47349562e-03\n",
      "    7.22936960e-03   1.91531435e-03   1.23833120e-03   7.74926739e-03\n",
      "    5.04526012e-02   8.79372004e-04   5.70086297e-04   5.26819436e-04\n",
      "    7.21597811e-03   1.70712869e-04   3.72256531e-04   4.49386105e-04\n",
      "    1.02626800e-03   1.93522463e-03   1.29032269e-04   6.92306261e-04\n",
      "    7.19127071e-04   6.38857426e-04   3.52991658e-04   4.21706261e-03\n",
      "    1.58465728e-02   9.04577412e-03   2.12468375e-02   3.19954153e-04\n",
      "    5.98488696e-05   2.49088735e-05   4.11564979e-04   3.16207297e-04\n",
      "    8.48314259e-03   1.16313586e-03   1.55264437e-02   1.81807252e-03\n",
      "    3.05205758e-04   2.28570236e-04   2.36722315e-03   6.46852143e-03\n",
      "    1.38459802e-02   3.44957371e-04   1.46893982e-03   2.64663361e-02\n",
      "    1.50015869e-04   6.06648915e-04   1.09198429e-02   4.42363264e-04\n",
      "    1.32760068e-03   5.87110817e-02   1.67762768e-02   1.65849546e-04\n",
      "    6.80772704e-04   5.91339252e-04   1.04606692e-02   6.91081025e-03\n",
      "    7.74654443e-04   3.81272439e-05   1.54560618e-02   2.18522489e-01\n",
      "    6.42584811e-04   2.49892124e-04   2.74806371e-04   1.51772995e-03\n",
      "    2.51950085e-04   3.31066083e-03   2.90281768e-03   5.22491464e-04\n",
      "    3.06107220e-03   8.52003321e-03   1.09155267e-03   3.19366599e-03\n",
      "    3.95665324e-04   2.11403915e-03   1.89704399e-04   6.67031331e-04\n",
      "    2.15466600e-03   8.50892102e-04   3.09459842e-03   3.70872626e-03\n",
      "    9.14813834e-04   2.65859789e-03   1.26212172e-03   2.44895369e-03\n",
      "    4.97518922e-04   3.54280323e-02   2.53422448e-04   1.92131147e-01\n",
      "    2.57920969e-04   1.04213716e-03   1.02555379e-03   2.27942131e-03\n",
      "    3.02142487e-03   2.61599780e-03   1.06486853e-03   3.74043826e-03\n",
      "    3.16867197e-04   8.52013764e-05   1.57585822e-03   1.38951011e-03\n",
      "    9.03121894e-04   1.51213876e-03   5.03758434e-03   9.40177870e-06\n",
      "    3.44961658e-02   1.05697121e-02   3.61790211e-04   2.62466259e-04\n",
      "    2.47184857e-04   9.40773898e-05   4.64302674e-03   8.34777020e-03\n",
      "    1.59813033e-03   9.21862258e-04   2.44308787e-04   4.40366202e-05\n",
      "    7.38824252e-03   3.44366359e-04   8.84718102e-05   1.11880777e-02\n",
      "    7.66737526e-03   3.93031252e-04   3.25705926e-03   1.40862251e-02\n",
      "    1.54226376e-02   2.22861327e-05   1.93922978e-03   6.42100567e-05\n",
      "    4.89120651e-03   1.50191656e-04   4.41852538e-03   4.20128490e-04\n",
      "    4.48672625e-04]]\n",
      "Dogue_de_bordeaux\n"
     ]
    }
   ],
   "source": [
    "from extract_bottleneck_features import *\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from glob import glob\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# Returns a vector containing all dog breeds and for each dog breed a probability of the provided image \n",
    "# matching that particular dog breed class.\n",
    "def Xception_predictions(img_path):\n",
    "    predicted_vector = model.predict(preprocess_input(path_to_tensor(img_path)))\n",
    "    print(predicted_vector)\n",
    "    return predicted_vector\n",
    "\n",
    "# Given any image returns the closest resembling dog breed\n",
    "def resembling_dog_breed(img_path):\n",
    "    predicted_vector = Xception_predictions(img_path)\n",
    "    return dog_names[np.argmax(predicted_vector)]\n",
    "\n",
    "my_dog_images = [\"images/Alfie-JackRussel.jpg\", \"images/Alfie-JackRussel_1.jpg\", \"images/Trex-YorkshireTerrier.jpg\", \"images/Trex-YorkshireTerrier_1.jpg\"]\n",
    "for dog_image in my_dog_images:\n",
    "    print(dog_image)\n",
    "    print(resembling_dog_breed(dog_image))\n",
    "\n",
    "my_family_images = [\"images/John.jpg\", \"images/Sue.jpg\", \"images/Sue1.jpg\", \"images/Oscar.jpg\"]\n",
    "for family_image in my_family_images:\n",
    "    print(family_image)\n",
    "    print(resembling_dog_breed(family_image))\n",
    "    \n",
    "# Images without humans, pets or animals, just 'dead' things\n",
    "other_images = [\"images/Sample_CNN.png\", \"images/Square.png\", \"images/Galaxy.jpg\"]\n",
    "for other_image in other_images:\n",
    "    print(other_image)\n",
    "    print(resembling_dog_breed(other_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great success but maybe we can do better by considering:\n",
    "- use of L1 or L2 regularization (https://keras.io/regularizers/)\n",
    "- better loss function\n",
    "- more aggresive data augmentation\n",
    "- more aggressive dropout\n",
    "- fine-tuning additional convolutional block/layers\n",
    "- batch normalisation\n",
    "- use ensembles (avg. multiple models)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
